{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08564c15-ddb8-4d2c-bed4-0bfade8f2afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pricing settings:\n",
      "Actual/365 (Fixed) day counter\n",
      "New York stock exchange calendar\n",
      "compounding: continuous\n",
      "frequency: annual\n",
      "\n",
      "Help on package model_settings:\n",
      "\n",
      "NAME\n",
      "    model_settings - a proprietary package of convenience wrappers for QuantLib\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    model_settings\n",
      "\n",
      "DATA\n",
      "    ms = <model_settings.model_settings.model_settings object>\n",
      "\n",
      "FILE\n",
      "    e:\\python\\lib\\site-packages\\model_settings\\__init__.py\n",
      "\n",
      "\n",
      "HDF5 error back trace\n",
      "\n",
      "  File \"D:\\bld\\hdf5_1717586849786\\work\\src\\H5F.c\", line 836, in H5Fopen\n",
      "    unable to synchronously open file\n",
      "  File \"D:\\bld\\hdf5_1717586849786\\work\\src\\H5F.c\", line 796, in H5F__open_api_common\n",
      "    unable to open file\n",
      "  File \"D:\\bld\\hdf5_1717586849786\\work\\src\\H5VLcallback.c\", line 3863, in H5VL_file_open\n",
      "    open failed\n",
      "  File \"D:\\bld\\hdf5_1717586849786\\work\\src\\H5VLcallback.c\", line 3675, in H5VL__file_open\n",
      "    open failed\n",
      "  File \"D:\\bld\\hdf5_1717586849786\\work\\src\\H5VLnative_file.c\", line 128, in H5VL__native_file_open\n",
      "    unable to open file\n",
      "  File \"D:\\bld\\hdf5_1717586849786\\work\\src\\H5Fint.c\", line 1910, in H5F_open\n",
      "    unable to lock the file\n",
      "  File \"D:\\bld\\hdf5_1717586849786\\work\\src\\H5FD.c\", line 2412, in H5FD_lock\n",
      "    driver lock request failed\n",
      "  File \"D:\\bld\\hdf5_1717586849786\\work\\src\\H5FDsec2.c\", line 941, in H5FD__sec2_lock\n",
      "    unable to lock file, errno = 0, error message = 'No error', Win32 GetLastError() = 33\n",
      "\n",
      "End of HDF5 error back trace\n",
      "\n",
      "Unable to open/create file 'E:\\git\\machine-learning-option-pricing\\historical_data\\historical_av_collection\\alphaVantage SPY.h5'\n",
      "\n",
      "retrying in...\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(Path()\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparent))\n\u001b[0;32m     32\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(Path()\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mparent))\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhistorical_av_key_collector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keys_df, symbol, h5_name\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhistorical_av_plot_vol_surface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_vol_surface\n\u001b[0;32m     35\u001b[0m h5_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(notebook_dir,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malphaVantage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mE:\\git\\machine-learning-option-pricing\\historical_data\\historical_av_collection\\historical_av_key_collector.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m-\u001b[39mi)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[43mstore\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     43\u001b[0m keys_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     44\u001b[0m     {\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspot_price\u001b[39m\u001b[38;5;124m'\u001b[39m:spot_price_keys,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m      }\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     54\u001b[0m keys_df \u001b[38;5;241m=\u001b[39m keys_df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_data_key\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'store' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import QuantLib as ql\n",
    "from pathlib import Path\n",
    "import modin.pandas as md\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from matplotlib import cm\n",
    "import model_settings\n",
    "help(model_settings)\n",
    "from model_settings import ms\n",
    "fontsize=4\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        'axes.labelsize': fontsize,\n",
    "        'xtick.labelsize': fontsize,\n",
    "        'ytick.labelsize': fontsize,\n",
    "        'figure.titlesize': fontsize,\n",
    "        'axes.linewidth': 1/3,\n",
    "        'lines.linewidth':1/2\n",
    "    }\n",
    ")\n",
    "pd.set_option(\"display.float_format\", \"{:.6f}\".format)\n",
    "warnings.filterwarnings(\"ignore\", \".*defaulting to pandas implementation.*\")\n",
    "notebook_dir = str(Path().resolve())\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "sys.path.append(str(Path().resolve().parent.parent))\n",
    "from historical_av_key_collector import keys_df, symbol, h5_name\n",
    "from historical_av_plot_vol_surface import plot_vol_surface\n",
    "h5_path = os.path.join(notebook_dir,f'alphaVantage {symbol}.h5')\n",
    "store = pd.HDFStore(h5_path)\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16afa9-1912-495a-a43f-4c826718f27f",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e277df0-06c4-47da-9e6e-a83ff5d41031",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_keys = keys_df.loc[:,['spot_price']].dropna()\n",
    "spots = pd.Series()\n",
    "store.open()\n",
    "for i,row in spot_keys.iterrows():\n",
    "    key = row['spot_price']\n",
    "    date = key[key.find('_',0)+1:key.find('/',1)]\n",
    "    spot_datetime = datetime.strptime(date,'%Y_%m_%d')\n",
    "    spot_price = float(store[key].iloc[0])\n",
    "    spots.loc[spot_datetime] = spot_price\n",
    "store.close()\n",
    "plt.figure(figsize=(4, 1), dpi=180)\n",
    "plt.plot(spots,color='black')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(symbol + ' options data available',fontsize=fontsize)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c02e94-1d89-44cb-9419-29cbaf644373",
   "metadata": {},
   "source": [
    "# calibrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319e2e4-97eb-49a8-8e16-02ed0e9735e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_keys = keys_df.copy().dropna(subset=['calibration_key','parameter_key'])\n",
    "calibrations = []\n",
    "parameters = {}\n",
    "while True:\n",
    "    try:\n",
    "        store.open()\n",
    "        for i,row in calibration_keys.iterrows():\n",
    "            key = row['calibration_key']\n",
    "            date = key[key.find('_',0)+1:key.find('/',1)].replace('_','-')\n",
    "            calibrations.append(store[row['calibration_key']])\n",
    "            parameters[date] = store[row['parameter_key']]\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('retrying in...')\n",
    "        for i in range(2):\n",
    "            print(2-i)\n",
    "            time.sleep(1)\n",
    "    finally:\n",
    "        store.close()\n",
    "\n",
    "calibrations = pd.concat(calibrations,ignore_index=True).dropna(subset='strike_price')\n",
    "calibrations['calculation_date'] = pd.to_datetime(calibrations['calculation_date'],format='%Y-%m-%d')\n",
    "calibrations = calibrations.set_index('calculation_date').sort_index()\n",
    "parameters = calibrations[['spot_price','theta','kappa','rho','eta','v0']].drop_duplicates()\n",
    "\n",
    "for col in parameters.columns:\n",
    "    plt.figure(figsize=(4,1), dpi=180)\n",
    "    plt.plot(calibrations[col], color='black')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(symbol + ' ' + col,fontsize=fontsize)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "print(f\"\\n{calibrations.reset_index().describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b96187-f795-4324-9896-c9db8589b228",
   "metadata": {},
   "source": [
    "## calibration testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bfbc1f-a60d-43aa-87fc-f45c0056f584",
   "metadata": {},
   "source": [
    "### original recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9754105-085f-42ba-af50-938dce261fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "problem_parameter = 'v0'\n",
    "problem_theshold = 100000\n",
    "problems = pd.Series(calibrations[problem_parameter][calibrations[problem_parameter]>problem_theshold].drop_duplicates().index).dt.strftime('/date_%Y_%m_%d/heston_calibration/calibration_results')\n",
    "dfs = {}\n",
    "with pd.HDFStore(h5_name) as store:\n",
    "    for key in problems:\n",
    "        dfs[key] = store[key]\n",
    "store.close()\n",
    "print('problem calibration(s):')\n",
    "for i,dfk in enumerate(dfs.keys()):\n",
    "    print(f\"{i}     {dfk}\")\n",
    "problem_keys = keys_df[keys_df['calibration_key'].isin(problems)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a9d7d-01ec-4c11-9c79-edfc63dfcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_idx = 0\n",
    "if problem_keys.shape[0] == 0:\n",
    "    print(f\"no issues with {problem_parameter}\")\n",
    "    pass\n",
    "else:\n",
    "    with pd.HDFStore(h5_name) as store:\n",
    "        calibration_key = problem_keys['calibration_key'].iloc[0]\n",
    "        surface = store[problem_keys['surface_key'].iloc[problem_idx]].drop_duplicates()\n",
    "        heston_parameters = store[problem_keys['parameter_key'].iloc[problem_idx]]\n",
    "        calibration = store[problem_keys['calibration_key'].iloc[problem_idx]]\n",
    "        raw_data = store[problem_keys['raw_data_key'].iloc[problem_idx]]\n",
    "        problem_spot = float(store[problem_keys['spot_price'].iloc[problem_idx]].iloc[0])\n",
    "        date = calibration_key[calibration_key.find('_',0)+1:calibration_key.find('/',1)].replace('_','-')\n",
    "        \n",
    "    store.close()\n",
    "    print(date)\n",
    "    previous_avgabs = np.mean(np.abs(calibration['error']))\n",
    "    print(\"original calibration:\")\n",
    "    plot_vol_surface(surface)\n",
    "    print(heston_parameters)\n",
    "    calculation_datetime = datetime.strptime(date,'%Y-%m-%d')\n",
    "    calculation_date = ql.Date(\n",
    "        calculation_datetime.day,\n",
    "        calculation_datetime.month,\n",
    "        calculation_datetime.year\n",
    "    )\n",
    "    printdate = str(calculation_datetime.strftime('%A, ')+str(calculation_date))\n",
    "    print(f\"average absolute error: {round(previous_avgabs,2)}\")\n",
    "    print(printdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42813444-2912-4ae1-9ac5-15fb1bc02977",
   "metadata": {},
   "source": [
    "### cleaning original raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6918e3c-cc4e-4f16-bd5f-d391197b0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if problem_keys.shape[0] == 0:\n",
    "    print(f\"no issues with {problem_parameter}\")\n",
    "    pass\n",
    "else:\n",
    "    spot = problem_spot\n",
    "    df = raw_data.copy()\n",
    "    df['volume'] = pd.to_numeric(df['volume'])\n",
    "    df['implied_volatility'] = pd.to_numeric(df['implied_volatility'])\n",
    "    df['strike'] = pd.to_numeric(df['strike'])\n",
    "    df['volume'] = pd.to_numeric(df['volume'])\n",
    "    df['expiration'] = pd.to_datetime(df['expiration'],format='%Y-%m-%d')\n",
    "    df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')\n",
    "    df['days_to_maturity'] = df['expiration'] - df['date']\n",
    "    df['days_to_maturity'] = df['days_to_maturity'] // np.timedelta64(1, 'D')\n",
    "    df['days_to_maturity'] = df['days_to_maturity'].astype('int64')\n",
    "    df = df[(df['days_to_maturity']>=30)&(df['days_to_maturity']<=400)]\n",
    "    df = df[['strike','implied_volatility','days_to_maturity','volume','type']]\n",
    "    df = df[df['volume']>0].copy()\n",
    "    df['spot_price'] = spot\n",
    "    df['moneyness'] = ms.vmoneyness(df['spot_price'],df['strike'],df['type'])\n",
    "    df = df[(df['moneyness']<0)&(df['moneyness']>-0.5)]\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            'strike':'strike_price',\n",
    "            'type':'w',\n",
    "            'implied_volatility':'volatility'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    indexed = df.copy().set_index(['strike_price','days_to_maturity'])\n",
    "\n",
    "    \n",
    "    T = np.sort(df['days_to_maturity'].unique()).tolist()\n",
    "    K = np.sort(df['strike_price'].unique()).tolist()\n",
    "    raw_surface = pd.DataFrame(\n",
    "        np.tile(np.nan,(len(K),len(T))),\n",
    "        index = K,\n",
    "        columns = T\n",
    "    )\n",
    "    for k in K:\n",
    "        for t in T:\n",
    "            if (k, t) in indexed.index:\n",
    "                raw_surface.loc[k, t] = indexed.loc[(k, t), 'volatility']\n",
    "    auto_surface = raw_surface.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277be566-b77d-4105-a738-e5c01bf89198",
   "metadata": {},
   "outputs": [],
   "source": [
    "if problem_keys.shape[0] == 0:\n",
    "    print(f\"no issues with {problem_parameter}\")\n",
    "    pass\n",
    "else:\n",
    "    vol_matrix = auto_surface.copy()\n",
    "    # spread = 0.15\n",
    "    # vol_matrix = vol_matrix[\n",
    "    #     (\n",
    "    #         (vol_matrix.index>(1-spread)*s)\n",
    "    #         &\n",
    "    #         (vol_matrix.index<(1+spread)*s)\n",
    "    #     )|\n",
    "    # ]\n",
    "    vol_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f929e41-fd1c-4085-a640-b4189f54edd8",
   "metadata": {},
   "source": [
    "### linearization of the volatility surface"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9faee894-64c8-41fa-b6fd-f3b9cbe39b2d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def linearize_vol_surface(surface):\n",
    "    s = problem_spot\n",
    "    K = np.array(surface.index)\n",
    "    atm_idx = pd.Series(abs(K-s)).sort_values().index.tolist()[0]\n",
    "    atm_vols = surface.iloc[atm_idx]\n",
    "    T = np.array(surface.columns)\n",
    "    \n",
    "    derman_coefs = pd.Series(np.empty(len(T),dtype=float),index=T)\n",
    "    for t in T:\n",
    "        vols = surface.loc[:,t]\n",
    "        x = np.array(vols.index)-s\n",
    "        y = vols - atm_vols.loc[t]\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        x = x.reshape(-1,1)\n",
    "        model.fit(x,y)\n",
    "        b = model.coef_[0]\n",
    "        derman_coefs.loc[t] = b\n",
    "    \n",
    "    derman_surface = pd.DataFrame(\n",
    "        np.empty((len(K),len(T)),dtype=float),\n",
    "        index=K,\n",
    "        columns=T\n",
    "    )\n",
    "    \n",
    "    for k in K:\n",
    "        moneyness = k-s\n",
    "        for t in T:\n",
    "            derman_surface.loc[k,t] = atm_vols.loc[t] + moneyness*derman_coefs.loc[t]\n",
    "    \n",
    "    plot_vol_surface(derman_surface)\n",
    "    vol_matrix = derman_surface.copy()\n",
    "    return vol_matrix\n",
    "vol_matrix = linearize_vol_surface(surface)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9e9410-ddaf-45f5-abb6-c4269c3e3546",
   "metadata": {},
   "source": [
    "## manual recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f51d1-0a19-4ebb-9276-04f821c24b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if problem_keys.shape[0] == 0:\n",
    "    print(f\"no issues with {problem_parameter}\")\n",
    "    pass\n",
    "else:\n",
    "    vol_matrix = vol_matrix.sort_index().drop_duplicates()\n",
    "    s = spot\n",
    "    T = vol_matrix.columns.tolist()\n",
    "    K = vol_matrix.index.tolist()\n",
    "    r = 0.04\n",
    "    g = 0.0\n",
    "    \n",
    "    ql.Settings.instance().evaluationDate = calculation_date\n",
    "    flat_ts, dividend_ts = ms.ql_ts_rg(r, g, calculation_date)\n",
    "    S_handle = ql.QuoteHandle(ql.SimpleQuote(s))\n",
    "    \n",
    "    heston_helpers = []\n",
    "    v0 = 0.01; kappa = 0.2; theta = 0.02; rho = -0.75; eta = 0.5;\n",
    "    process = ql.HestonProcess(\n",
    "        flat_ts,\n",
    "        dividend_ts,\n",
    "        S_handle,\n",
    "        v0,                # Initial volatility\n",
    "        kappa,             # Mean reversion speed\n",
    "        theta,             # Long-run variance (volatility squared)\n",
    "        eta,               # Volatility of the volatility\n",
    "        rho                # Correlation between asset and volatility\n",
    "    )\n",
    "    model = ql.HestonModel(process)\n",
    "    engine = ql.AnalyticHestonEngine(model)\n",
    "    \n",
    "    for t in T:\n",
    "        for k in K:\n",
    "            p = ql.Period(int(t),ql.Days)\n",
    "            volatility = vol_matrix.loc[k,t]\n",
    "            helper = ql.HestonModelHelper(\n",
    "                p, ms.calendar, float(s), k, \n",
    "                ql.QuoteHandle(ql.SimpleQuote(volatility)), \n",
    "                flat_ts, \n",
    "                dividend_ts\n",
    "                )\n",
    "            helper.setPricingEngine(engine)\n",
    "            heston_helpers.append(helper)\n",
    "    \n",
    "    lm = ql.LevenbergMarquardt(1e-8, 1e-8, 1e-8)\n",
    "    \n",
    "    \n",
    "    model.calibrate(heston_helpers, lm,\n",
    "                      ql.EndCriteria(1000, 50, 1.0e-8,1.0e-8, 1.0e-8))\n",
    "    \n",
    "    theta, kappa, eta, rho, v0 = model.params()\n",
    "    heston_parameters = pd.Series(\n",
    "        [theta, kappa, eta, rho, v0],\n",
    "        index = ['theta', 'kappa', 'eta', 'rho', 'v0'],\n",
    "        dtype = float\n",
    "    )\n",
    "    calibration_test_data = df.copy()\n",
    "    calibration_test_data['spot_price'] = s\n",
    "    calibration_test_data['risk_free_rate'] = r\n",
    "    calibration_test_data['dividend_rate'] = g\n",
    "    calibration_test_data = calibration_test_data[calibration_test_data['days_to_maturity'].isin(df['days_to_maturity'])]\n",
    "    calibration_test_data[heston_parameters.index.tolist()] = np.tile(heston_parameters,(calibration_test_data.shape[0],1))\n",
    "    calibration_test_data.loc[:,'moneyness'] = ms.vmoneyness(\n",
    "        calibration_test_data['spot_price'].values,\n",
    "        calibration_test_data['strike_price'].values,\n",
    "        calibration_test_data['w'].values\n",
    "    )\n",
    "    calibration_test_data['calculation_date'] = date\n",
    "    calibration_test_data['black_scholes'] = ms.vector_black_scholes(calibration_test_data)\n",
    "    calibration_test_data['heston_price'] = ms.vector_heston_price(calibration_test_data)\n",
    "    calibration_test_data.loc[:,'error'] = calibration_test_data['heston_price'].values - calibration_test_data['black_scholes'].values\n",
    "    avg = np.mean(np.abs(calibration_test_data['error']))\n",
    "\n",
    "    print(\"recalibrated:\")\n",
    "    plot_vol_surface(vol_matrix)\n",
    "    print(f\"\\n{printdate}\\n{heston_parameters}\\n\\naverage absolute error: {round(avg,3)}\")\n",
    "    print(f\"previous error: {round(previous_avgabs,3)}\\nchange: {round(avg-previous_avgabs,4)}\")\n",
    "    print(f\"\\n\\ncalibration testing dataset:\\n{calibration_test_data.describe()}\")\n",
    "    print(f\"\\n{calibration_test_data.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e2a04-7b85-465f-82d1-01fdd79d2ab0",
   "metadata": {},
   "source": [
    "### ENTRY REPLACEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f13fd-bd25-46d4-8610-706bfd08499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_calibration_data():\n",
    "    results_replacement_key = problem_keys.iloc[problem_idx]['calibration_key']\n",
    "    parameter_replacement_key = problem_keys.iloc[problem_idx]['parameter_key']\n",
    "    surface_replacement_key = problem_keys.iloc[problem_idx]['surface_key']\n",
    "    with pd.HDFStore(h5_name) as store:\n",
    "        store.put(surface_replacement_key,vol_matrix,format='table',append=False)\n",
    "        store.put(parameter_replacement_key,heston_parameters,format='table',append=False)\n",
    "        store.put(results_replacement_key,calibration_test_data,format='table',append=False)\n",
    "        print(f'{results_replacement_key} | {parameter_replacement_key} | {surface_replacement_key}:     replaced')\n",
    "    store.close()\n",
    "try:\n",
    "    print(printdate)\n",
    "except Exception:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
