{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d2f96b-933e-4b58-be45-8212f496a6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  2024-12-03 115353819604 inital cboe spx relative asian\n",
      "1  2024-12-03 221708375538 inital cboe spx relative barrier\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model_settings import ms\n",
    "from pathlib import Path\n",
    "ms.find_root(Path())\n",
    "models_dir = os.path.join(ms.root,ms.trained_models)\n",
    "models = [f for f in os.listdir(models_dir) if f.find('.')==-1]\n",
    "for i,m in enumerate(models):\n",
    "    print(f\"{i}  {m}\")\n",
    "# i = int(input('select model: '))\n",
    "i=0\n",
    "model_dir = os.path.join(models_dir,models[i])\n",
    "pickle = os.path.join(model_dir,models[i]+'.pkl')\n",
    "\n",
    "def test_performance(model,net):\n",
    "    inpred = net.predict(model['train_X'])\n",
    "    intar = model['train_data'][model['target_name']].values\n",
    "    indiff = inpred-intar\n",
    "    inRMSE = np.sqrt(np.mean(indiff**2))\n",
    "    inMAE = np.mean(np.abs(indiff))\n",
    "    print(f\"in sample\\n   RMSE:\\n      {inRMSE}\")\n",
    "    print(f\"   MAE:\\n      {inMAE}\")\n",
    "\n",
    "    outpred = net.predict(model['test_X'])\n",
    "    outtar = model['test_data'][model['target_name']].values\n",
    "    outdiff = outpred-outtar\n",
    "    outRMSE = np.sqrt(np.mean(outdiff**2))\n",
    "    outMAE = np.mean(np.abs(outdiff))\n",
    "    print(f\"out of sample\\n   RMSE:\\n      {outRMSE}\")\n",
    "    print(f\"   MAE:\\n      {outMAE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c9e4b4-1b59-4662-9545-a25e90d3aa60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = joblib.load(pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8d6ed8-f822-4f1c-a347-bde2e73ab552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'sgd',\n",
       " 'activation': 'relu',\n",
       " 'max_iter': 500,\n",
       " 'random_state': 1312,\n",
       " 'early_stopping': True,\n",
       " 'hidden_layer_sizes': (20,),\n",
       " 'learning_rate': 'adaptive',\n",
       " 'learning_rate_init': 0.1,\n",
       " 'n_iter_no_change': 20,\n",
       " 'tol': 0.0001,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['mlp_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af4c6e7-3d6e-43da-bf54-e80df9cce429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'solver': 'sgd', 'alpha': 0.0001, 'batch_size': 'auto', 'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'power_t': 0.5, 'max_iter': 500, 'loss': 'squared_error', 'hidden_layer_sizes': (20,), 'shuffle': True, 'random_state': 1312, 'tol': 0.0001, 'verbose': False, 'warm_start': False, 'momentum': 0.9, 'nesterovs_momentum': True, 'early_stopping': True, 'validation_fraction': 0.1, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-08, 'n_iter_no_change': 20, 'max_fun': 15000}\n",
      "\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('StandardScaler',\n",
      "                                                  StandardScaler(),\n",
      "                                                  ['days_to_maturity',\n",
      "                                                   'fixing_frequency',\n",
      "                                                   'past_fixings',\n",
      "                                                   'risk_free_rate',\n",
      "                                                   'dividend_rate', 'kappa',\n",
      "                                                   'theta', 'rho', 'eta', 'v0',\n",
      "                                                   'relative_spot']),\n",
      "                                                 ('OneHotEncoder',\n",
      "                                                  OneHotEncoder(sparse_output=False),\n",
      "                                                  ['averaging_type', 'w'])])),\n",
      "                ('regressor',\n",
      "                 MLPRegressor(early_stopping=True, hidden_layer_sizes=(20,),\n",
      "                              learning_rate='adaptive', learning_rate_init=0.1,\n",
      "                              max_iter=500, n_iter_no_change=20,\n",
      "                              random_state=1312, solver='sgd'))])\n",
      "\n",
      "out activation:  identity\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "mlp = MLPRegressor(**model['mlp_params'])\n",
    "identity = Pipeline([\n",
    "            (\"preprocessor\", model['preprocessor']),\n",
    "            (\"regressor\", mlp)\n",
    "        ])\n",
    "print(identity[1].__dict__)\n",
    "print()\n",
    "print(identity.fit(model['train_X'],model['train_y']))\n",
    "print()\n",
    "print('out activation: ',identity[1].__dict__['out_activation_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7407c2e-5111-4f70-9818-0762e5dd0992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'solver': 'sgd', 'alpha': 0.0001, 'batch_size': 'auto', 'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'power_t': 0.5, 'max_iter': 500, 'loss': 'squared_error', 'hidden_layer_sizes': (20,), 'shuffle': True, 'random_state': 1312, 'tol': 0.0001, 'verbose': False, 'warm_start': False, 'momentum': 0.9, 'nesterovs_momentum': True, 'early_stopping': True, 'validation_fraction': 0.1, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-08, 'n_iter_no_change': 20, 'max_fun': 15000}\n",
      "\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('StandardScaler',\n",
      "                                                  StandardScaler(),\n",
      "                                                  ['days_to_maturity',\n",
      "                                                   'fixing_frequency',\n",
      "                                                   'past_fixings',\n",
      "                                                   'risk_free_rate',\n",
      "                                                   'dividend_rate', 'kappa',\n",
      "                                                   'theta', 'rho', 'eta', 'v0',\n",
      "                                                   'relative_spot']),\n",
      "                                                 ('OneHotEncoder',\n",
      "                                                  OneHotEncoder(sparse_output=False),\n",
      "                                                  ['averaging_type', 'w'])])),\n",
      "                ('regressor',\n",
      "                 MLPRegressor(early_stopping=True, hidden_layer_sizes=(20,),\n",
      "                              learning_rate='adaptive', learning_rate_init=0.1,\n",
      "                              max_iter=500, n_iter_no_change=20,\n",
      "                              random_state=1312, solver='sgd'))])\n",
      "\n",
      "out activation:  relu\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(**model['mlp_params'])\n",
    "relu = Pipeline([\n",
    "            (\"preprocessor\", model['preprocessor']),\n",
    "            (\"regressor\", mlp)\n",
    "        ])\n",
    "print(relu[1].__dict__)\n",
    "print()\n",
    "print(relu.fit(model['train_X'],model['train_y']))\n",
    "print()\n",
    "relu[1].__dict__['out_activation_'] = 'relu'\n",
    "print('out activation: ',relu[1].__dict__['out_activation_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6388dfb7-2d81-494a-b8dd-56ca19501a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0001, 'batch_size': 'auto', 'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'power_t': 0.5, 'max_iter': 500, 'loss': 'squared_error', 'hidden_layer_sizes': (20,), 'shuffle': True, 'random_state': 1312, 'tol': 0.0001, 'verbose': False, 'warm_start': False, 'momentum': 0.9, 'nesterovs_momentum': True, 'early_stopping': True, 'validation_fraction': 0.1, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-08, 'n_iter_no_change': 20, 'max_fun': 15000}\n",
      "\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('StandardScaler',\n",
      "                                                  StandardScaler(),\n",
      "                                                  ['days_to_maturity',\n",
      "                                                   'fixing_frequency',\n",
      "                                                   'past_fixings',\n",
      "                                                   'risk_free_rate',\n",
      "                                                   'dividend_rate', 'kappa',\n",
      "                                                   'theta', 'rho', 'eta', 'v0',\n",
      "                                                   'relative_spot']),\n",
      "                                                 ('OneHotEncoder',\n",
      "                                                  OneHotEncoder(sparse_output=False),\n",
      "                                                  ['averaging_type', 'w'])])),\n",
      "                ('regressor',\n",
      "                 MLPRegressor(activation='logistic', early_stopping=True,\n",
      "                              hidden_layer_sizes=(20,),\n",
      "                              learning_rate='adaptive', learning_rate_init=0.1,\n",
      "                              max_iter=500, n_iter_no_change=20,\n",
      "                              random_state=1312, solver='sgd'))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model['mlp_params']['activation']='logistic'\n",
    "mlp = MLPRegressor(**model['mlp_params'])\n",
    "logistic = Pipeline([\n",
    "            (\"preprocessor\", model['preprocessor']),\n",
    "            (\"regressor\", mlp)\n",
    "        ])\n",
    "print(logistic[1].__dict__)\n",
    "print()\n",
    "print(logistic.fit(model['train_X'],model['train_y']))\n",
    "print()\n",
    "# logistic[1].__dict__['out_activation_'] = 'logistic'\n",
    "# print('out activation: ',logistic[1].__dict__['out_activation_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d9b5e6e-1c04-4064-bbb2-caf661247244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'logistic',\n",
       " 'solver': 'sgd',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'learning_rate': 'adaptive',\n",
       " 'learning_rate_init': 0.1,\n",
       " 'power_t': 0.5,\n",
       " 'max_iter': 500,\n",
       " 'loss': 'squared_error',\n",
       " 'hidden_layer_sizes': (20,),\n",
       " 'shuffle': True,\n",
       " 'random_state': 1312,\n",
       " 'tol': 0.0001,\n",
       " 'verbose': False,\n",
       " 'warm_start': False,\n",
       " 'momentum': 0.9,\n",
       " 'nesterovs_momentum': True,\n",
       " 'early_stopping': True,\n",
       " 'validation_fraction': 0.1,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-08,\n",
       " 'n_iter_no_change': 20,\n",
       " 'max_fun': 15000,\n",
       " 'n_features_in_': 15,\n",
       " 'n_outputs_': 1,\n",
       " '_random_state': RandomState(MT19937) at 0x21B52CE9E40,\n",
       " 'n_iter_': 380,\n",
       " 't_': 8064360,\n",
       " 'n_layers_': 3,\n",
       " 'out_activation_': 'identity',\n",
       " 'coefs_': [array([[ 1.46010044e-02,  1.54924153e-01, -5.46431999e-03,\n",
       "           1.25273547e-01,  4.25145995e-03, -9.99363221e-02,\n",
       "          -1.03760127e-01,  1.84360097e-01,  8.40064735e-02,\n",
       "          -1.85727755e-01,  2.70692710e-02, -1.74755461e-01,\n",
       "          -1.25429155e-01, -1.08787527e-01, -2.12919614e-01,\n",
       "          -3.01130217e-03,  9.82333475e-02,  3.34592888e-02,\n",
       "          -7.98778532e-02,  9.02699379e-02],\n",
       "         [-6.13501376e-02,  1.12164089e-01, -1.53282648e-01,\n",
       "          -1.07013850e-01, -1.67408502e-03, -1.25200659e-01,\n",
       "          -4.20562234e-02,  6.64928652e-02, -1.10658535e-01,\n",
       "           6.75986873e-02,  1.58062041e-01,  8.03094434e-02,\n",
       "          -1.70093721e-01,  6.34291031e-04,  1.77871235e-03,\n",
       "           4.25397330e-03,  1.14910443e-01, -1.96626691e-01,\n",
       "           7.51882105e-02,  3.81666995e-02],\n",
       "         [ 6.16961851e-02, -1.37027173e-01, -1.80748183e-01,\n",
       "           1.13680486e-01, -2.23681970e-02, -1.62308847e-01,\n",
       "           1.56948343e-01,  8.89595781e-02,  1.51530628e-01,\n",
       "          -4.91472012e-02, -1.20005969e-01, -3.15752419e-02,\n",
       "           7.89707465e-02, -1.31521676e-01,  1.85431177e-01,\n",
       "           9.09104636e-03,  2.30693285e-01,  2.06550180e-01,\n",
       "           1.94969010e-01, -2.04535286e-01],\n",
       "         [-1.65680761e-01,  1.19296315e-01,  6.22298215e-02,\n",
       "          -3.62124039e-02, -2.14462051e-03, -2.19973235e-02,\n",
       "           1.52135616e-01, -7.79395120e-02, -1.80152226e-01,\n",
       "           1.42249023e-01,  3.29275130e-02, -4.37188015e-02,\n",
       "          -8.78341981e-02, -2.13982505e-01, -2.34754560e-02,\n",
       "           3.83418748e-04, -3.17766011e-02,  1.50432742e-01,\n",
       "           3.44231562e-02, -4.91338492e-02],\n",
       "         [ 1.60397318e-01,  1.76905354e-01,  9.71822505e-02,\n",
       "          -3.26624472e-03, -1.53121332e-04,  1.56783571e-01,\n",
       "          -1.90294940e-01, -1.24918821e-01, -1.93302160e-01,\n",
       "          -7.86862894e-02,  2.08741472e-01, -5.81632794e-02,\n",
       "          -1.05772830e-01, -3.60921626e-02, -1.65766047e-01,\n",
       "          -6.36396795e-04,  3.47383598e-02, -7.80239277e-02,\n",
       "          -6.42973236e-02,  6.19154798e-02],\n",
       "         [-9.95242426e-02,  7.61487827e-02, -4.24991211e-02,\n",
       "          -1.05734757e-01, -4.59622197e-03,  6.50471431e-02,\n",
       "          -2.82065040e-02,  1.06242296e-01,  6.60508838e-03,\n",
       "           7.36856773e-02, -4.95636401e-02,  5.70859969e-02,\n",
       "           4.46682672e-02, -2.03037789e-01,  1.04059748e-01,\n",
       "           7.00185350e-03, -1.28693263e-01,  3.79602573e-02,\n",
       "          -1.12599821e-02,  9.65874950e-02],\n",
       "         [-5.85460289e-02, -1.37936200e-01, -2.18372040e-02,\n",
       "           7.57594189e-02, -3.79523300e-03, -4.87373150e-02,\n",
       "           1.27635307e-01, -1.71003410e-01, -7.06194504e-02,\n",
       "          -8.49186037e-02,  4.84470289e-02,  1.38775725e-01,\n",
       "           3.98790294e-02,  9.79932092e-02, -9.30235255e-02,\n",
       "           7.76434382e-03,  1.30420321e-01, -1.21019013e-01,\n",
       "          -6.17918559e-02, -1.37490472e-01],\n",
       "         [ 1.67344863e-01,  2.52251071e-02, -7.54547987e-03,\n",
       "           6.79530028e-02, -1.40173042e-04, -2.04233933e-01,\n",
       "           4.58952241e-02,  7.02711129e-02, -1.95257129e-01,\n",
       "           2.76568087e-02,  2.32302131e-01,  4.83666876e-02,\n",
       "          -8.49988644e-03, -5.16338924e-02,  1.30228414e-01,\n",
       "          -7.15161514e-04, -1.23756318e-01, -1.45147836e-01,\n",
       "          -1.37858468e-02,  2.19013857e-01],\n",
       "         [-2.39278319e-01,  5.24338470e-03,  1.51444294e-02,\n",
       "           6.35142719e-02, -3.34249241e-04, -3.38630470e-02,\n",
       "          -1.24433307e-02,  1.04917004e-01,  5.60397893e-02,\n",
       "          -2.24301134e-01, -1.44883237e-01, -1.89151671e-01,\n",
       "           8.86248635e-02,  1.82247213e-01, -7.54030112e-02,\n",
       "          -8.71314593e-04,  2.21234173e-01, -1.29128362e-01,\n",
       "           1.92463732e-02, -1.59479323e-01],\n",
       "         [-1.13241058e-01, -1.07690748e-01,  1.28670010e-02,\n",
       "           5.39456964e-02, -2.89831175e-03, -1.36927454e-01,\n",
       "           1.86229904e-01, -1.29087674e-01,  1.42349369e-01,\n",
       "           1.69162993e-01, -1.03528255e-01,  2.37294468e-02,\n",
       "           1.20550749e-02,  1.07485334e-01, -1.99641635e-01,\n",
       "          -7.83511274e-04,  8.23664734e-02, -1.36092971e-01,\n",
       "          -5.13514780e-02,  9.50945967e-02],\n",
       "         [-1.29896110e-01, -1.87349209e-01,  3.48487150e-02,\n",
       "          -9.35624085e-05, -2.03880645e+00, -8.51014046e-02,\n",
       "           6.12565117e-02, -2.07867667e-01, -9.60073710e-02,\n",
       "          -1.61411208e-01, -1.20684630e-02, -5.79601675e-02,\n",
       "          -1.27048891e-02,  5.58758451e-02,  7.09761880e-02,\n",
       "          -1.19421149e+00, -8.32158783e-02, -8.92682516e-02,\n",
       "           6.98241503e-02,  7.93544704e-02],\n",
       "         [ 4.05548708e-03, -1.80255765e-01, -1.59796178e-01,\n",
       "          -9.49228328e-02, -7.75851817e-01, -1.40651275e-01,\n",
       "          -1.89090182e-01, -7.79636932e-03, -1.35743108e-01,\n",
       "           9.87731169e-02, -2.38985879e-01, -2.51881649e-03,\n",
       "          -1.93694365e-01,  1.19686345e-02, -1.56921266e-01,\n",
       "           6.98266516e-01,  1.36696012e-01,  2.15869094e-01,\n",
       "           6.62553677e-02,  1.89665380e-01],\n",
       "         [ 1.43966470e-01,  1.90849312e-01,  1.41377294e-01,\n",
       "          -8.61684645e-02, -7.73276511e-01,  3.80816597e-02,\n",
       "           1.63818460e-01, -1.26124267e-01, -8.73820377e-02,\n",
       "          -1.60113188e-01,  1.62198230e-01,  1.43322083e-01,\n",
       "          -1.36429498e-01, -1.02200845e-01,  1.97099911e-01,\n",
       "           6.98421509e-01,  1.28653597e-01,  9.33599961e-02,\n",
       "          -2.44597601e-01,  1.47940053e-01],\n",
       "         [ 1.40068313e-01, -1.45421111e-01, -1.61242650e-01,\n",
       "          -4.44894642e-01, -1.10625062e+00,  9.43240152e-02,\n",
       "          -2.24764819e-03,  2.35080799e-01,  4.41819770e-02,\n",
       "          -7.23114992e-02, -5.16950783e-03, -8.87441018e-02,\n",
       "          -1.12463862e-01,  9.81808633e-02, -1.79503535e-01,\n",
       "          -1.58404040e+00, -2.94551109e-01, -8.90626359e-02,\n",
       "          -2.77887542e-01, -3.77768551e-01],\n",
       "         [-1.63344287e-01,  6.49949333e-02, -4.99177731e-02,\n",
       "           3.43241616e-01, -6.80809029e-01,  3.14303181e-01,\n",
       "          -3.26792442e-01, -3.29259895e-01,  2.90033222e-01,\n",
       "          -4.81470914e-02,  1.17765443e-01,  2.46957393e-01,\n",
       "           1.18058296e-01, -1.07969410e-01,  5.29073577e-02,\n",
       "           2.93348479e+00,  1.81976641e-01,  8.17235421e-02,\n",
       "           5.07018697e-01,  3.02993899e-02]]),\n",
       "  array([[-0.20537657],\n",
       "         [ 0.10378072],\n",
       "         [ 0.17675782],\n",
       "         [ 0.5681169 ],\n",
       "         [ 1.43686438],\n",
       "         [ 0.10661387],\n",
       "         [-0.21957948],\n",
       "         [-0.17449965],\n",
       "         [ 0.16536626],\n",
       "         [ 0.03636952],\n",
       "         [ 0.13954638],\n",
       "         [ 0.33502995],\n",
       "         [ 0.20718012],\n",
       "         [-0.16513246],\n",
       "         [ 0.15368918],\n",
       "         [-1.88456088],\n",
       "         [ 0.4227796 ],\n",
       "         [ 0.11833689],\n",
       "         [ 0.60740164],\n",
       "         [ 0.32448233]])],\n",
       " 'intercepts_': [array([ 0.02826192, -0.1032272 , -0.29833626, -0.08211869, -1.57929985,\n",
       "         -0.04649821,  0.02251887, -0.04189895, -0.07533144, -0.2042503 ,\n",
       "          0.11205144, -0.01374963,  0.21963963,  0.00974052,  0.01660807,\n",
       "          1.55271982, -0.21983446, -0.17883883,  0.00493901, -0.02249235]),\n",
       "  array([0.26651959])],\n",
       " 'loss_curve_': [np.float64(0.0344727279115789),\n",
       "  np.float64(0.032485571577736475),\n",
       "  np.float64(0.031367865246343454),\n",
       "  np.float64(0.027243035289216202),\n",
       "  np.float64(0.015448957000200408),\n",
       "  np.float64(0.0039304673262289145),\n",
       "  np.float64(0.0011890865288207873),\n",
       "  np.float64(0.0008477180461916793),\n",
       "  np.float64(0.0007701128064777935),\n",
       "  np.float64(0.0007426632166719152),\n",
       "  np.float64(0.0007329022086884442),\n",
       "  np.float64(0.000727138369800907),\n",
       "  np.float64(0.0007167003421940672),\n",
       "  np.float64(0.0007149212251587809),\n",
       "  np.float64(0.0007078705111755801),\n",
       "  np.float64(0.0007042373287604757),\n",
       "  np.float64(0.0007033185264927443),\n",
       "  np.float64(0.0006996761995352839),\n",
       "  np.float64(0.0007009656526599),\n",
       "  np.float64(0.0006930025006420058),\n",
       "  np.float64(0.000692730293417318),\n",
       "  np.float64(0.0006908882995122473),\n",
       "  np.float64(0.0006879955051650611),\n",
       "  np.float64(0.0006877039155751153),\n",
       "  np.float64(0.0006862900998980288),\n",
       "  np.float64(0.0006850083334337382),\n",
       "  np.float64(0.0006817012560243073),\n",
       "  np.float64(0.0006802024237905365),\n",
       "  np.float64(0.0006817764960245625),\n",
       "  np.float64(0.0006789398352703786),\n",
       "  np.float64(0.0006786515635478159),\n",
       "  np.float64(0.0006783748420364291),\n",
       "  np.float64(0.0006778800142685362),\n",
       "  np.float64(0.0006748311775904937),\n",
       "  np.float64(0.0006738393614877378),\n",
       "  np.float64(0.0006735237517593565),\n",
       "  np.float64(0.0006735316458452049),\n",
       "  np.float64(0.0006706669829029878),\n",
       "  np.float64(0.0006695238023149964),\n",
       "  np.float64(0.0006686168024192582),\n",
       "  np.float64(0.0006687405486806133),\n",
       "  np.float64(0.0006658806051312829),\n",
       "  np.float64(0.0006644931201938507),\n",
       "  np.float64(0.0006641769610695876),\n",
       "  np.float64(0.0006638645054125007),\n",
       "  np.float64(0.0006639773595761445),\n",
       "  np.float64(0.0006625149705477111),\n",
       "  np.float64(0.0006606292363427554),\n",
       "  np.float64(0.000659303479232502),\n",
       "  np.float64(0.0006613548940453891),\n",
       "  np.float64(0.0006588607209328879),\n",
       "  np.float64(0.0006574629059792946),\n",
       "  np.float64(0.0006560834583945447),\n",
       "  np.float64(0.0006561198874145404),\n",
       "  np.float64(0.000656043378491648),\n",
       "  np.float64(0.0006542305731808697),\n",
       "  np.float64(0.0006545745154016858),\n",
       "  np.float64(0.0006522847229028878),\n",
       "  np.float64(0.00065169849385008),\n",
       "  np.float64(0.0006495321416652079),\n",
       "  np.float64(0.0006490407343073038),\n",
       "  np.float64(0.0006444393934684752),\n",
       "  np.float64(0.0006476523685531137),\n",
       "  np.float64(0.0006439346173237661),\n",
       "  np.float64(0.0006416329215058397),\n",
       "  np.float64(0.0006421679188833209),\n",
       "  np.float64(0.0006429867867838804),\n",
       "  np.float64(0.0006416590384175163),\n",
       "  np.float64(0.0006392603044769134),\n",
       "  np.float64(0.000636733715639394),\n",
       "  np.float64(0.0006352223326846215),\n",
       "  np.float64(0.0006310965126403225),\n",
       "  np.float64(0.0006316186370118297),\n",
       "  np.float64(0.0006302175442247116),\n",
       "  np.float64(0.0006271855000251062),\n",
       "  np.float64(0.0006272319305423148),\n",
       "  np.float64(0.0006256530617102012),\n",
       "  np.float64(0.0006252223408525748),\n",
       "  np.float64(0.0006222316717303752),\n",
       "  np.float64(0.0006195266102187692),\n",
       "  np.float64(0.0006164503067620863),\n",
       "  np.float64(0.0006144506820358604),\n",
       "  np.float64(0.0006113891989122359),\n",
       "  np.float64(0.0006082409281952861),\n",
       "  np.float64(0.0006091061740868128),\n",
       "  np.float64(0.0006011589485682879),\n",
       "  np.float64(0.0006002393704633327),\n",
       "  np.float64(0.0005985117311718791),\n",
       "  np.float64(0.000596476156838573),\n",
       "  np.float64(0.00059285307430632),\n",
       "  np.float64(0.0005897936908887618),\n",
       "  np.float64(0.0005871471443870923),\n",
       "  np.float64(0.0005842833436750205),\n",
       "  np.float64(0.000580820163930538),\n",
       "  np.float64(0.000577633178464039),\n",
       "  np.float64(0.0005730045357534927),\n",
       "  np.float64(0.0005689301868750438),\n",
       "  np.float64(0.0005661405474566987),\n",
       "  np.float64(0.000561560564201559),\n",
       "  np.float64(0.000557288012156923),\n",
       "  np.float64(0.00055324289214178),\n",
       "  np.float64(0.0005491475118220026),\n",
       "  np.float64(0.0005451634972595753),\n",
       "  np.float64(0.00054063989064913),\n",
       "  np.float64(0.0005352749527058437),\n",
       "  np.float64(0.0005305354571583271),\n",
       "  np.float64(0.0005275655134798724),\n",
       "  np.float64(0.0005201211905583443),\n",
       "  np.float64(0.0005162270462902451),\n",
       "  np.float64(0.0005095507985453294),\n",
       "  np.float64(0.0005047155450920015),\n",
       "  np.float64(0.0005023037698933106),\n",
       "  np.float64(0.0004956734592691404),\n",
       "  np.float64(0.000488802552548314),\n",
       "  np.float64(0.0004831658835289413),\n",
       "  np.float64(0.00047778967982453613),\n",
       "  np.float64(0.0004713309601748388),\n",
       "  np.float64(0.0004661624716017713),\n",
       "  np.float64(0.0004607528729994739),\n",
       "  np.float64(0.00045445707860900983),\n",
       "  np.float64(0.0004485143739628296),\n",
       "  np.float64(0.0004450253588811046),\n",
       "  np.float64(0.00043777599962044816),\n",
       "  np.float64(0.00043144586759723524),\n",
       "  np.float64(0.0004268604757265462),\n",
       "  np.float64(0.00042157101766559553),\n",
       "  np.float64(0.000414930151067605),\n",
       "  np.float64(0.00040840606117481477),\n",
       "  np.float64(0.00040270880883988856),\n",
       "  np.float64(0.00039821794277115625),\n",
       "  np.float64(0.000394068848512148),\n",
       "  np.float64(0.0003877204906670231),\n",
       "  np.float64(0.0003816560291722225),\n",
       "  np.float64(0.0003761691625109939),\n",
       "  np.float64(0.0003702482858167583),\n",
       "  np.float64(0.000365730312799293),\n",
       "  np.float64(0.00036142241839393145),\n",
       "  np.float64(0.0003560059153031355),\n",
       "  np.float64(0.00035083047425349856),\n",
       "  np.float64(0.00034605242528580355),\n",
       "  np.float64(0.00034106194347098486),\n",
       "  np.float64(0.000337496733017013),\n",
       "  np.float64(0.0003324881296880269),\n",
       "  np.float64(0.00032789636657078083),\n",
       "  np.float64(0.00032352258632899607),\n",
       "  np.float64(0.0003192783256620913),\n",
       "  np.float64(0.00031530324652343444),\n",
       "  np.float64(0.00031223371423655264),\n",
       "  np.float64(0.00030779340912055335),\n",
       "  np.float64(0.0003037214952329748),\n",
       "  np.float64(0.0003003610391187177),\n",
       "  np.float64(0.00029625041903237885),\n",
       "  np.float64(0.00029480335005868793),\n",
       "  np.float64(0.00028967811408665145),\n",
       "  np.float64(0.0002865048040683234),\n",
       "  np.float64(0.00028486570985048246),\n",
       "  np.float64(0.000280121329901989),\n",
       "  np.float64(0.00027760162281354817),\n",
       "  np.float64(0.00027377328224470395),\n",
       "  np.float64(0.0002716694826025074),\n",
       "  np.float64(0.0002692548208259504),\n",
       "  np.float64(0.00026570567256246577),\n",
       "  np.float64(0.0002637094225197149),\n",
       "  np.float64(0.0002606489981008369),\n",
       "  np.float64(0.00025852837164495776),\n",
       "  np.float64(0.00025547541802178403),\n",
       "  np.float64(0.0002538679983467987),\n",
       "  np.float64(0.00025127220228301296),\n",
       "  np.float64(0.0002485944363055195),\n",
       "  np.float64(0.00024664732831263105),\n",
       "  np.float64(0.0002451159413098121),\n",
       "  np.float64(0.00024298873397592718),\n",
       "  np.float64(0.00024077120314431176),\n",
       "  np.float64(0.00023924060366558838),\n",
       "  np.float64(0.00023847115436625483),\n",
       "  np.float64(0.00023555416213657957),\n",
       "  np.float64(0.00023369569987290688),\n",
       "  np.float64(0.0002321094853897574),\n",
       "  np.float64(0.00023014647383990045),\n",
       "  np.float64(0.00022872794388790734),\n",
       "  np.float64(0.0002268070245667918),\n",
       "  np.float64(0.00022647656685547944),\n",
       "  np.float64(0.00022475575775392494),\n",
       "  np.float64(0.00022294082968112448),\n",
       "  np.float64(0.0002220270239498431),\n",
       "  np.float64(0.00021993555311907822),\n",
       "  np.float64(0.00021977077526342295),\n",
       "  np.float64(0.0002200125884618201),\n",
       "  np.float64(0.0002163276420445321),\n",
       "  np.float64(0.00021567778516297598),\n",
       "  np.float64(0.0002138716513198503),\n",
       "  np.float64(0.00021348242327452315),\n",
       "  np.float64(0.0002125026039159768),\n",
       "  np.float64(0.0002120004285458853),\n",
       "  np.float64(0.0002110112720622137),\n",
       "  np.float64(0.00020955109227330728),\n",
       "  np.float64(0.0002087957698041584),\n",
       "  np.float64(0.00020734742034349239),\n",
       "  np.float64(0.00020682481329349162),\n",
       "  np.float64(0.00020613161486391065),\n",
       "  np.float64(0.00020481075295941532),\n",
       "  np.float64(0.0002040233597067565),\n",
       "  np.float64(0.0002027027676560759),\n",
       "  np.float64(0.0002022960347725778),\n",
       "  np.float64(0.00020201459353562596),\n",
       "  np.float64(0.00020155467228598724),\n",
       "  np.float64(0.00020005923610928072),\n",
       "  np.float64(0.00019967469879424754),\n",
       "  np.float64(0.0001990472579747756),\n",
       "  np.float64(0.00019797600593044916),\n",
       "  np.float64(0.00019809030488818975),\n",
       "  np.float64(0.0001969287078254441),\n",
       "  np.float64(0.0001954206682254495),\n",
       "  np.float64(0.00019467279199681902),\n",
       "  np.float64(0.00019474544020500683),\n",
       "  np.float64(0.00019461223506366053),\n",
       "  np.float64(0.0001942654087536428),\n",
       "  np.float64(0.0001940915590892397),\n",
       "  np.float64(0.00019410133875639673),\n",
       "  np.float64(0.0001940420831782583),\n",
       "  np.float64(0.0001937442940781811),\n",
       "  np.float64(0.0001939481398725271),\n",
       "  np.float64(0.0001936374890324034),\n",
       "  np.float64(0.00019359038476578333),\n",
       "  np.float64(0.00019333441907771668),\n",
       "  np.float64(0.0001933089221117242),\n",
       "  np.float64(0.00019301303628048357),\n",
       "  np.float64(0.00019289138153210842),\n",
       "  np.float64(0.00019291749388460164),\n",
       "  np.float64(0.00019282694292843209),\n",
       "  np.float64(0.00019275824488178725),\n",
       "  np.float64(0.00019286523002878434),\n",
       "  np.float64(0.00019251120804596972),\n",
       "  np.float64(0.00019201695861537242),\n",
       "  np.float64(0.00019203786722189306),\n",
       "  np.float64(0.0001920882180511384),\n",
       "  np.float64(0.00019201702337235158),\n",
       "  np.float64(0.00019192599208638073),\n",
       "  np.float64(0.00019194213373773382),\n",
       "  np.float64(0.00019191069015331928),\n",
       "  np.float64(0.0001919146531831244),\n",
       "  np.float64(0.00019192195861965296),\n",
       "  np.float64(0.00019184085009288945),\n",
       "  np.float64(0.00019184030779695668),\n",
       "  np.float64(0.0001918099666680198),\n",
       "  np.float64(0.00019179263321543783),\n",
       "  np.float64(0.00019170922002873008),\n",
       "  np.float64(0.0001916976984258242),\n",
       "  np.float64(0.00019166077856741179),\n",
       "  np.float64(0.00019165620167835027),\n",
       "  np.float64(0.00019166236941615245),\n",
       "  np.float64(0.00019163662063496507),\n",
       "  np.float64(0.0001916380331920541),\n",
       "  np.float64(0.00019163741945235754),\n",
       "  np.float64(0.0001914601348204191),\n",
       "  np.float64(0.00019146990593972018),\n",
       "  np.float64(0.00019147598231276884),\n",
       "  np.float64(0.00019148249576135995),\n",
       "  np.float64(0.00019146146800896343),\n",
       "  np.float64(0.00019146403119383598),\n",
       "  np.float64(0.0001914585921662937),\n",
       "  np.float64(0.00019144181970297836),\n",
       "  np.float64(0.00019143363019100693),\n",
       "  np.float64(0.00019146198602308976),\n",
       "  np.float64(0.000191429873057932),\n",
       "  np.float64(0.00019141825088100768),\n",
       "  np.float64(0.00019142467250133228),\n",
       "  np.float64(0.00019146566968378923),\n",
       "  np.float64(0.00019140342745202368),\n",
       "  np.float64(0.00019141203549341527),\n",
       "  np.float64(0.00019141912905553865),\n",
       "  np.float64(0.00019139796314008195),\n",
       "  np.float64(0.00019139605367693451),\n",
       "  np.float64(0.00019139878789985388),\n",
       "  np.float64(0.00019140375520782605),\n",
       "  np.float64(0.0001913614371819528),\n",
       "  np.float64(0.00019136092571719478),\n",
       "  np.float64(0.00019135807877272937),\n",
       "  np.float64(0.00019136084308540895),\n",
       "  np.float64(0.0001913582212605011),\n",
       "  np.float64(0.0001913524135921749),\n",
       "  np.float64(0.000191353584835106),\n",
       "  np.float64(0.0001913585534908584),\n",
       "  np.float64(0.0001913558644790477),\n",
       "  np.float64(0.0001913587896966449),\n",
       "  np.float64(0.00019134865186038282),\n",
       "  np.float64(0.0001913538027566449),\n",
       "  np.float64(0.00019135066720709634),\n",
       "  np.float64(0.00019135123974143008),\n",
       "  np.float64(0.0001913481975838973),\n",
       "  np.float64(0.00019134724228633075),\n",
       "  np.float64(0.00019134908054734237),\n",
       "  np.float64(0.000191345750246972),\n",
       "  np.float64(0.00019134397810004623),\n",
       "  np.float64(0.00019134112444852585),\n",
       "  np.float64(0.00019135367155294458),\n",
       "  np.float64(0.00019133575859403554),\n",
       "  np.float64(0.00019133567983897315),\n",
       "  np.float64(0.000191335112670061),\n",
       "  np.float64(0.0001913358527400013),\n",
       "  np.float64(0.00019133663102821748),\n",
       "  np.float64(0.00019133495215652003),\n",
       "  np.float64(0.0001913352526893158),\n",
       "  np.float64(0.00019133511354369278),\n",
       "  np.float64(0.00019133431730550016),\n",
       "  np.float64(0.00019133395320101618),\n",
       "  np.float64(0.00019133332834818717),\n",
       "  np.float64(0.00019133482256835396),\n",
       "  np.float64(0.0001913346685539969),\n",
       "  np.float64(0.00019133312134665827),\n",
       "  np.float64(0.000191333356141716),\n",
       "  np.float64(0.00019133284875452608),\n",
       "  np.float64(0.00019133245534312578),\n",
       "  np.float64(0.00019133301691560834),\n",
       "  np.float64(0.00019133331266036387),\n",
       "  np.float64(0.00019133264526662461),\n",
       "  np.float64(0.00019133220632384866),\n",
       "  np.float64(0.00019133084149985556),\n",
       "  np.float64(0.00019133072296352712),\n",
       "  np.float64(0.00019133097685964623),\n",
       "  np.float64(0.0001913306914512318),\n",
       "  np.float64(0.00019133063776627588),\n",
       "  np.float64(0.0001913307329161662),\n",
       "  np.float64(0.00019133059246097584),\n",
       "  np.float64(0.0001913305985020639),\n",
       "  np.float64(0.00019133064896195262),\n",
       "  np.float64(0.00019133083647978732),\n",
       "  np.float64(0.0001913306137977307),\n",
       "  np.float64(0.00019133055884417214),\n",
       "  np.float64(0.00019133047945387339),\n",
       "  np.float64(0.00019133057200373734),\n",
       "  np.float64(0.00019133033504129137),\n",
       "  np.float64(0.00019133053240576544),\n",
       "  np.float64(0.00019133018159837577),\n",
       "  np.float64(0.0001913302865497242),\n",
       "  np.float64(0.00019133053435778184),\n",
       "  np.float64(0.00019133055838293163),\n",
       "  np.float64(0.00019133013338052022),\n",
       "  np.float64(0.00019132994279126686),\n",
       "  np.float64(0.00019132988090885095),\n",
       "  np.float64(0.00019132986751862517),\n",
       "  np.float64(0.000191329909248028),\n",
       "  np.float64(0.00019132986914620264),\n",
       "  np.float64(0.00019132985402919942),\n",
       "  np.float64(0.00019132987610628513),\n",
       "  np.float64(0.00019132985553501123),\n",
       "  np.float64(0.0001913298475582841),\n",
       "  np.float64(0.00019132981213960466),\n",
       "  np.float64(0.0001913298111455244),\n",
       "  np.float64(0.00019132983360668345),\n",
       "  np.float64(0.0001913298261089305),\n",
       "  np.float64(0.00019132979477573585),\n",
       "  np.float64(0.00019132978868434248),\n",
       "  np.float64(0.00019132981457444442),\n",
       "  np.float64(0.0001913298132781845),\n",
       "  np.float64(0.0001913298292243966),\n",
       "  np.float64(0.00019132988167791263),\n",
       "  np.float64(0.00019132977544132222),\n",
       "  np.float64(0.0001913297673692777),\n",
       "  np.float64(0.00019132971386886838),\n",
       "  np.float64(0.00019132969827348828),\n",
       "  np.float64(0.00019132970038409852),\n",
       "  np.float64(0.00019132969647622048),\n",
       "  np.float64(0.00019132969826924056),\n",
       "  np.float64(0.0001913296958493934),\n",
       "  np.float64(0.00019132969302800517),\n",
       "  np.float64(0.000191329691125502),\n",
       "  np.float64(0.00019132969290260455),\n",
       "  np.float64(0.00019132968963301184),\n",
       "  np.float64(0.00019132969351565304),\n",
       "  np.float64(0.00019132968728786275),\n",
       "  np.float64(0.00019132968971775972),\n",
       "  np.float64(0.00019132968262520794),\n",
       "  np.float64(0.0001913296901214205),\n",
       "  np.float64(0.0001913296775021226),\n",
       "  np.float64(0.00019132968408524907),\n",
       "  np.float64(0.00019132967602516633),\n",
       "  np.float64(0.0001913296780354002),\n",
       "  np.float64(0.00019132967813882153),\n",
       "  np.float64(0.00019132967116419994)],\n",
       " '_no_improvement_count': 21,\n",
       " 'validation_scores_': [0.2664367671436155,\n",
       "  0.25635418597570303,\n",
       "  0.2877140860032198,\n",
       "  0.480367469877794,\n",
       "  0.8166814080144837,\n",
       "  0.9599156398451973,\n",
       "  0.978289660902653,\n",
       "  0.9814563566572488,\n",
       "  0.9814002138858372,\n",
       "  0.9784317864624603,\n",
       "  0.9804010552946931,\n",
       "  0.9826220541109042,\n",
       "  0.9821926535054526,\n",
       "  0.9825344883424437,\n",
       "  0.9834720626901683,\n",
       "  0.9796751911972976,\n",
       "  0.9832294507863095,\n",
       "  0.9758001006725081,\n",
       "  0.983525091687715,\n",
       "  0.9837452929748022,\n",
       "  0.9835516361915229,\n",
       "  0.9814573888383799,\n",
       "  0.9824573278414848,\n",
       "  0.9839002268511255,\n",
       "  0.9825191194111784,\n",
       "  0.983607518408965,\n",
       "  0.9830694128506923,\n",
       "  0.983867998918107,\n",
       "  0.9826988154098295,\n",
       "  0.9840256111015452,\n",
       "  0.9836060290041424,\n",
       "  0.9837794982318333,\n",
       "  0.9839268035743569,\n",
       "  0.9821130228380663,\n",
       "  0.9842392050647423,\n",
       "  0.9842182685607038,\n",
       "  0.9837257834763407,\n",
       "  0.984280014049488,\n",
       "  0.9842273586353978,\n",
       "  0.9830062233062316,\n",
       "  0.9837261531240367,\n",
       "  0.9831389912398564,\n",
       "  0.9841709900308082,\n",
       "  0.9837574323654859,\n",
       "  0.9814440963111822,\n",
       "  0.9835911203335703,\n",
       "  0.9842215328990676,\n",
       "  0.9829987895612748,\n",
       "  0.984422451050683,\n",
       "  0.983423251645253,\n",
       "  0.9845323327800204,\n",
       "  0.9844752035782206,\n",
       "  0.9844358356133477,\n",
       "  0.9827652955122294,\n",
       "  0.9841735836807991,\n",
       "  0.9823092607340055,\n",
       "  0.9840543484557529,\n",
       "  0.984614390028448,\n",
       "  0.9845975265015744,\n",
       "  0.9842312936253258,\n",
       "  0.9847409613123818,\n",
       "  0.9847817240627118,\n",
       "  0.9848374613245517,\n",
       "  0.984263252692013,\n",
       "  0.9844785176221875,\n",
       "  0.9815420346587422,\n",
       "  0.9784402184795232,\n",
       "  0.9838387179922606,\n",
       "  0.9840304387521531,\n",
       "  0.984828446051324,\n",
       "  0.9851133024404369,\n",
       "  0.9844436645096641,\n",
       "  0.9849799687553357,\n",
       "  0.9836922093900168,\n",
       "  0.9848247736220407,\n",
       "  0.9852169712224274,\n",
       "  0.9812419909035454,\n",
       "  0.9851695456889598,\n",
       "  0.9826703708460481,\n",
       "  0.9854329830724616,\n",
       "  0.984893789477635,\n",
       "  0.9852869969035186,\n",
       "  0.9848777624691224,\n",
       "  0.9849296651213225,\n",
       "  0.9849805680819801,\n",
       "  0.9857234778476368,\n",
       "  0.9845449823595149,\n",
       "  0.9859215848941385,\n",
       "  0.9860208650435811,\n",
       "  0.9858829654569068,\n",
       "  0.9839886144713822,\n",
       "  0.9858653584540985,\n",
       "  0.9858236039352496,\n",
       "  0.9851987300197013,\n",
       "  0.9864842614342992,\n",
       "  0.9859938832309786,\n",
       "  0.9865632221651917,\n",
       "  0.9866084897762424,\n",
       "  0.9861535320138037,\n",
       "  0.985181970532559,\n",
       "  0.9866988256936352,\n",
       "  0.9870104174823141,\n",
       "  0.9866003138879217,\n",
       "  0.9872283648569865,\n",
       "  0.9866872842171656,\n",
       "  0.9833836553311647,\n",
       "  0.9875164190598348,\n",
       "  0.9871003058932175,\n",
       "  0.9878012195630974,\n",
       "  0.9876257116510487,\n",
       "  0.9864886706875403,\n",
       "  0.9880208669231203,\n",
       "  0.988316382269098,\n",
       "  0.9882126098972597,\n",
       "  0.9882587690359315,\n",
       "  0.9884067233343565,\n",
       "  0.988664582945452,\n",
       "  0.9887834324720867,\n",
       "  0.9889123845746509,\n",
       "  0.9888626742853058,\n",
       "  0.9892562245128446,\n",
       "  0.9880856353439667,\n",
       "  0.9890989258335489,\n",
       "  0.9869245864677181,\n",
       "  0.9898185476904174,\n",
       "  0.9890433700502803,\n",
       "  0.9890170964618681,\n",
       "  0.9901754979128422,\n",
       "  0.9896840078405332,\n",
       "  0.9877603202711528,\n",
       "  0.9898963241764925,\n",
       "  0.9899911148487601,\n",
       "  0.9905854196644205,\n",
       "  0.9908244901369742,\n",
       "  0.9912908814085033,\n",
       "  0.9905150655534151,\n",
       "  0.9914738213633618,\n",
       "  0.9907288043587121,\n",
       "  0.9916279910663248,\n",
       "  0.9910092851975006,\n",
       "  0.9919804810958515,\n",
       "  0.9920735035953134,\n",
       "  0.992212245084822,\n",
       "  0.9922631371110472,\n",
       "  0.992155199480657,\n",
       "  0.9925060466409901,\n",
       "  0.9903611139272155,\n",
       "  0.9922132565573307,\n",
       "  0.9924942698521924,\n",
       "  0.992824262761169,\n",
       "  0.9929179121542014,\n",
       "  0.9921349877502731,\n",
       "  0.9929315262717985,\n",
       "  0.993156426333311,\n",
       "  0.9916435969865602,\n",
       "  0.9932693155480758,\n",
       "  0.9933829552335285,\n",
       "  0.9933374108572229,\n",
       "  0.9931565314918798,\n",
       "  0.9931974044150355,\n",
       "  0.99356829154008,\n",
       "  0.9936067001307769,\n",
       "  0.9936136436807562,\n",
       "  0.9935565009066609,\n",
       "  0.9937525135616024,\n",
       "  0.9939243219264157,\n",
       "  0.9936988019703694,\n",
       "  0.993929409667207,\n",
       "  0.9941824873819747,\n",
       "  0.9941578922468486,\n",
       "  0.994181682787214,\n",
       "  0.993936705586669,\n",
       "  0.9937743448571398,\n",
       "  0.9940909229330673,\n",
       "  0.9943106887681058,\n",
       "  0.9944899321829871,\n",
       "  0.9942507968745817,\n",
       "  0.9943414814010337,\n",
       "  0.994385927267658,\n",
       "  0.9945925365221324,\n",
       "  0.9945591005267153,\n",
       "  0.9939323841458139,\n",
       "  0.9946202636267395,\n",
       "  0.994786620199734,\n",
       "  0.9948210123374726,\n",
       "  0.9948615746256054,\n",
       "  0.9907363477269081,\n",
       "  0.9948734603007301,\n",
       "  0.9948510412198008,\n",
       "  0.9948784351224397,\n",
       "  0.9950138153286414,\n",
       "  0.9950153047504892,\n",
       "  0.9942674231525545,\n",
       "  0.993496605916352,\n",
       "  0.9950699775653544,\n",
       "  0.9941596487284936,\n",
       "  0.995122327430402,\n",
       "  0.9948112398480051,\n",
       "  0.9951368883207229,\n",
       "  0.995163288621031,\n",
       "  0.9950493710886372,\n",
       "  0.995239000765,\n",
       "  0.9950324881528098,\n",
       "  0.9951684905977836,\n",
       "  0.9952541442313316,\n",
       "  0.995316152765261,\n",
       "  0.9952662691340807,\n",
       "  0.9946718521863115,\n",
       "  0.9952047624653653,\n",
       "  0.9950267972667414,\n",
       "  0.995399551523662,\n",
       "  0.9954011912432994,\n",
       "  0.9954226986230794,\n",
       "  0.995351300438676,\n",
       "  0.9953836028135973,\n",
       "  0.9954286627954606,\n",
       "  0.9953191242694169,\n",
       "  0.9954413221259503,\n",
       "  0.9954101248782707,\n",
       "  0.9954436769088664,\n",
       "  0.9954067564542981,\n",
       "  0.9954471166776115,\n",
       "  0.9954120632009967,\n",
       "  0.9954294064414396,\n",
       "  0.9954328194093727,\n",
       "  0.9954573430593283,\n",
       "  0.9954549872344033,\n",
       "  0.9954538178191472,\n",
       "  0.9954645368535949,\n",
       "  0.9954661644896315,\n",
       "  0.995474242048623,\n",
       "  0.9954736320054984,\n",
       "  0.9954796380047398,\n",
       "  0.9954742511358615,\n",
       "  0.9954758382302928,\n",
       "  0.995478981858152,\n",
       "  0.9954796670263619,\n",
       "  0.9954810893668714,\n",
       "  0.9954818591390633,\n",
       "  0.9954819706372584,\n",
       "  0.9954801542369632,\n",
       "  0.9954826872007556,\n",
       "  0.9954819959345511,\n",
       "  0.9954844592099843,\n",
       "  0.9954797981479392,\n",
       "  0.9954867852634215,\n",
       "  0.9954830186575143,\n",
       "  0.9954858982405422,\n",
       "  0.99548589726386,\n",
       "  0.9954878763995441,\n",
       "  0.9954850950009205,\n",
       "  0.9954888963147993,\n",
       "  0.9954888188236207,\n",
       "  0.9954858487861017,\n",
       "  0.995489644702056,\n",
       "  0.9954914244431792,\n",
       "  0.9954911037964819,\n",
       "  0.9954912687772625,\n",
       "  0.9954914995305552,\n",
       "  0.9954908002583229,\n",
       "  0.9954917395949204,\n",
       "  0.9954916380618238,\n",
       "  0.9954916861683719,\n",
       "  0.9954915501151995,\n",
       "  0.9954913978679119,\n",
       "  0.9954916876243622,\n",
       "  0.9954917690387122,\n",
       "  0.9954916762895488,\n",
       "  0.9954920047224906,\n",
       "  0.9954923998513349,\n",
       "  0.9954922615380358,\n",
       "  0.9954913463729798,\n",
       "  0.9954923905157219,\n",
       "  0.995492844374198,\n",
       "  0.9954931731567895,\n",
       "  0.9954929301116368,\n",
       "  0.995492873200387,\n",
       "  0.9954928284483096,\n",
       "  0.9954927677641905,\n",
       "  0.9954927926233568,\n",
       "  0.9954928212891051,\n",
       "  0.9954927930678877,\n",
       "  0.995492928649598,\n",
       "  0.9954929507094552,\n",
       "  0.9954929637114813,\n",
       "  0.9954929991470725,\n",
       "  0.9954928110800425,\n",
       "  0.9954929548177013,\n",
       "  0.9954928602251223,\n",
       "  0.9954928317163761,\n",
       "  0.9954928034972633,\n",
       "  0.9954929803938798,\n",
       "  0.9954930928053369,\n",
       "  0.9954929718810068,\n",
       "  0.9954929622943771,\n",
       "  0.9954929490918923,\n",
       "  0.9954929621233699,\n",
       "  0.9954929513947175,\n",
       "  0.9954929815478063,\n",
       "  0.995492980048103,\n",
       "  0.9954929732527392,\n",
       "  0.9954929876595071,\n",
       "  0.9954930043726972,\n",
       "  0.9954929625083296,\n",
       "  0.9954929941933717,\n",
       "  0.9954929853898761,\n",
       "  0.9954929708034439,\n",
       "  0.9954929578367545,\n",
       "  0.995492937093208,\n",
       "  0.9954929587133078,\n",
       "  0.9954930062020679,\n",
       "  0.9954929972806508,\n",
       "  0.9954929902644042,\n",
       "  0.995493018794858,\n",
       "  0.995492979268734,\n",
       "  0.9954929827041429,\n",
       "  0.9954930056814668,\n",
       "  0.9954930039620508,\n",
       "  0.9954930009205931,\n",
       "  0.9954930085079272,\n",
       "  0.9954930113877767,\n",
       "  0.9954930086802064,\n",
       "  0.9954930097292972,\n",
       "  0.9954930078337032,\n",
       "  0.995493006682769,\n",
       "  0.9954930056482328,\n",
       "  0.9954930090847175,\n",
       "  0.995493005715574,\n",
       "  0.9954929994379107,\n",
       "  0.9954930069286612,\n",
       "  0.9954930030941084,\n",
       "  0.995493013208524,\n",
       "  0.9954930163018691,\n",
       "  0.9954930310481761,\n",
       "  0.9954930336456322,\n",
       "  0.9954930298004757,\n",
       "  0.9954930324993685,\n",
       "  0.9954930312052656,\n",
       "  0.9954930294887435,\n",
       "  0.9954930290913225,\n",
       "  0.9954930312432455,\n",
       "  0.995493032037209,\n",
       "  0.995493032902377,\n",
       "  0.9954930331011445,\n",
       "  0.9954930328678194,\n",
       "  0.995493031021171,\n",
       "  0.99549303305085,\n",
       "  0.9954930336025676,\n",
       "  0.9954930333964397,\n",
       "  0.9954930336161207,\n",
       "  0.9954930347795441,\n",
       "  0.9954930341391935,\n",
       "  0.9954930346063933,\n",
       "  0.9954930321019695,\n",
       "  0.995493032260565,\n",
       "  0.9954930317125518,\n",
       "  0.9954930325451046,\n",
       "  0.995493033297606,\n",
       "  0.9954930329693273,\n",
       "  0.9954930330792653,\n",
       "  0.9954930326272593,\n",
       "  0.9954930324613349,\n",
       "  0.9954930324569807,\n",
       "  0.9954930323595904,\n",
       "  0.995493032360396,\n",
       "  0.9954930326924225,\n",
       "  0.9954930326399964,\n",
       "  0.9954930327888828,\n",
       "  0.9954930326209124,\n",
       "  0.9954930325896625,\n",
       "  0.9954930327677398,\n",
       "  0.995493032429329,\n",
       "  0.9954930321970406,\n",
       "  0.9954930320966103,\n",
       "  0.9954930320857724,\n",
       "  0.9954930318573223,\n",
       "  0.9954930319923804,\n",
       "  0.9954930319511149,\n",
       "  0.9954930319480095,\n",
       "  0.9954930322111859],\n",
       " 'best_validation_score_': 0.9954931731567895,\n",
       " 'best_loss_': None,\n",
       " '_optimizer': <sklearn.neural_network._stochastic_optimizers.SGDOptimizer at 0x21b52bae6f0>,\n",
       " 'loss_': np.float64(0.00019132967116419994),\n",
       " '_best_coefs': [array([[ 1.46010044e-02,  1.54924153e-01, -5.46431999e-03,\n",
       "           1.25273547e-01,  4.25145995e-03, -9.99363221e-02,\n",
       "          -1.03760127e-01,  1.84360097e-01,  8.40064735e-02,\n",
       "          -1.85727755e-01,  2.70692710e-02, -1.74755461e-01,\n",
       "          -1.25429155e-01, -1.08787527e-01, -2.12919614e-01,\n",
       "          -3.01130217e-03,  9.82333475e-02,  3.34592888e-02,\n",
       "          -7.98778532e-02,  9.02699379e-02],\n",
       "         [-6.13501376e-02,  1.12164089e-01, -1.53282648e-01,\n",
       "          -1.07013850e-01, -1.67408502e-03, -1.25200659e-01,\n",
       "          -4.20562234e-02,  6.64928652e-02, -1.10658535e-01,\n",
       "           6.75986873e-02,  1.58062041e-01,  8.03094434e-02,\n",
       "          -1.70093721e-01,  6.34291031e-04,  1.77871235e-03,\n",
       "           4.25397330e-03,  1.14910443e-01, -1.96626691e-01,\n",
       "           7.51882105e-02,  3.81666995e-02],\n",
       "         [ 6.16961851e-02, -1.37027173e-01, -1.80748183e-01,\n",
       "           1.13680486e-01, -2.23681970e-02, -1.62308847e-01,\n",
       "           1.56948343e-01,  8.89595781e-02,  1.51530628e-01,\n",
       "          -4.91472012e-02, -1.20005969e-01, -3.15752419e-02,\n",
       "           7.89707465e-02, -1.31521676e-01,  1.85431177e-01,\n",
       "           9.09104636e-03,  2.30693285e-01,  2.06550180e-01,\n",
       "           1.94969010e-01, -2.04535286e-01],\n",
       "         [-1.65680761e-01,  1.19296315e-01,  6.22298215e-02,\n",
       "          -3.62124039e-02, -2.14462051e-03, -2.19973235e-02,\n",
       "           1.52135616e-01, -7.79395120e-02, -1.80152226e-01,\n",
       "           1.42249023e-01,  3.29275130e-02, -4.37188015e-02,\n",
       "          -8.78341981e-02, -2.13982505e-01, -2.34754560e-02,\n",
       "           3.83418748e-04, -3.17766011e-02,  1.50432742e-01,\n",
       "           3.44231562e-02, -4.91338492e-02],\n",
       "         [ 1.60397318e-01,  1.76905354e-01,  9.71822505e-02,\n",
       "          -3.26624472e-03, -1.53121332e-04,  1.56783571e-01,\n",
       "          -1.90294940e-01, -1.24918821e-01, -1.93302160e-01,\n",
       "          -7.86862894e-02,  2.08741472e-01, -5.81632794e-02,\n",
       "          -1.05772830e-01, -3.60921626e-02, -1.65766047e-01,\n",
       "          -6.36396795e-04,  3.47383598e-02, -7.80239277e-02,\n",
       "          -6.42973236e-02,  6.19154798e-02],\n",
       "         [-9.95242426e-02,  7.61487827e-02, -4.24991211e-02,\n",
       "          -1.05734757e-01, -4.59622197e-03,  6.50471431e-02,\n",
       "          -2.82065040e-02,  1.06242296e-01,  6.60508838e-03,\n",
       "           7.36856773e-02, -4.95636401e-02,  5.70859969e-02,\n",
       "           4.46682672e-02, -2.03037789e-01,  1.04059748e-01,\n",
       "           7.00185350e-03, -1.28693263e-01,  3.79602573e-02,\n",
       "          -1.12599821e-02,  9.65874950e-02],\n",
       "         [-5.85460289e-02, -1.37936200e-01, -2.18372040e-02,\n",
       "           7.57594189e-02, -3.79523300e-03, -4.87373150e-02,\n",
       "           1.27635307e-01, -1.71003410e-01, -7.06194504e-02,\n",
       "          -8.49186037e-02,  4.84470289e-02,  1.38775725e-01,\n",
       "           3.98790294e-02,  9.79932092e-02, -9.30235255e-02,\n",
       "           7.76434382e-03,  1.30420321e-01, -1.21019013e-01,\n",
       "          -6.17918559e-02, -1.37490472e-01],\n",
       "         [ 1.67344863e-01,  2.52251071e-02, -7.54547987e-03,\n",
       "           6.79530028e-02, -1.40173042e-04, -2.04233933e-01,\n",
       "           4.58952241e-02,  7.02711129e-02, -1.95257129e-01,\n",
       "           2.76568087e-02,  2.32302131e-01,  4.83666876e-02,\n",
       "          -8.49988644e-03, -5.16338924e-02,  1.30228414e-01,\n",
       "          -7.15161514e-04, -1.23756318e-01, -1.45147836e-01,\n",
       "          -1.37858468e-02,  2.19013857e-01],\n",
       "         [-2.39278319e-01,  5.24338470e-03,  1.51444294e-02,\n",
       "           6.35142719e-02, -3.34249241e-04, -3.38630470e-02,\n",
       "          -1.24433307e-02,  1.04917004e-01,  5.60397893e-02,\n",
       "          -2.24301134e-01, -1.44883237e-01, -1.89151671e-01,\n",
       "           8.86248635e-02,  1.82247213e-01, -7.54030112e-02,\n",
       "          -8.71314593e-04,  2.21234173e-01, -1.29128362e-01,\n",
       "           1.92463732e-02, -1.59479323e-01],\n",
       "         [-1.13241058e-01, -1.07690748e-01,  1.28670010e-02,\n",
       "           5.39456964e-02, -2.89831175e-03, -1.36927454e-01,\n",
       "           1.86229904e-01, -1.29087674e-01,  1.42349369e-01,\n",
       "           1.69162993e-01, -1.03528255e-01,  2.37294468e-02,\n",
       "           1.20550749e-02,  1.07485334e-01, -1.99641635e-01,\n",
       "          -7.83511274e-04,  8.23664734e-02, -1.36092971e-01,\n",
       "          -5.13514780e-02,  9.50945967e-02],\n",
       "         [-1.29896110e-01, -1.87349209e-01,  3.48487150e-02,\n",
       "          -9.35624085e-05, -2.03880645e+00, -8.51014046e-02,\n",
       "           6.12565117e-02, -2.07867667e-01, -9.60073710e-02,\n",
       "          -1.61411208e-01, -1.20684630e-02, -5.79601675e-02,\n",
       "          -1.27048891e-02,  5.58758451e-02,  7.09761880e-02,\n",
       "          -1.19421149e+00, -8.32158783e-02, -8.92682516e-02,\n",
       "           6.98241503e-02,  7.93544704e-02],\n",
       "         [ 4.05548708e-03, -1.80255765e-01, -1.59796178e-01,\n",
       "          -9.49228328e-02, -7.75851817e-01, -1.40651275e-01,\n",
       "          -1.89090182e-01, -7.79636932e-03, -1.35743108e-01,\n",
       "           9.87731169e-02, -2.38985879e-01, -2.51881649e-03,\n",
       "          -1.93694365e-01,  1.19686345e-02, -1.56921266e-01,\n",
       "           6.98266516e-01,  1.36696012e-01,  2.15869094e-01,\n",
       "           6.62553677e-02,  1.89665380e-01],\n",
       "         [ 1.43966470e-01,  1.90849312e-01,  1.41377294e-01,\n",
       "          -8.61684645e-02, -7.73276511e-01,  3.80816597e-02,\n",
       "           1.63818460e-01, -1.26124267e-01, -8.73820377e-02,\n",
       "          -1.60113188e-01,  1.62198230e-01,  1.43322083e-01,\n",
       "          -1.36429498e-01, -1.02200845e-01,  1.97099911e-01,\n",
       "           6.98421509e-01,  1.28653597e-01,  9.33599961e-02,\n",
       "          -2.44597601e-01,  1.47940053e-01],\n",
       "         [ 1.40068313e-01, -1.45421111e-01, -1.61242650e-01,\n",
       "          -4.44894642e-01, -1.10625062e+00,  9.43240152e-02,\n",
       "          -2.24764819e-03,  2.35080799e-01,  4.41819770e-02,\n",
       "          -7.23114992e-02, -5.16950783e-03, -8.87441018e-02,\n",
       "          -1.12463862e-01,  9.81808633e-02, -1.79503535e-01,\n",
       "          -1.58404040e+00, -2.94551109e-01, -8.90626359e-02,\n",
       "          -2.77887542e-01, -3.77768551e-01],\n",
       "         [-1.63344287e-01,  6.49949333e-02, -4.99177731e-02,\n",
       "           3.43241616e-01, -6.80809029e-01,  3.14303181e-01,\n",
       "          -3.26792442e-01, -3.29259895e-01,  2.90033222e-01,\n",
       "          -4.81470914e-02,  1.17765443e-01,  2.46957393e-01,\n",
       "           1.18058296e-01, -1.07969410e-01,  5.29073577e-02,\n",
       "           2.93348479e+00,  1.81976641e-01,  8.17235421e-02,\n",
       "           5.07018697e-01,  3.02993899e-02]]),\n",
       "  array([[-0.20537657],\n",
       "         [ 0.10378072],\n",
       "         [ 0.17675782],\n",
       "         [ 0.5681169 ],\n",
       "         [ 1.43686438],\n",
       "         [ 0.10661387],\n",
       "         [-0.21957948],\n",
       "         [-0.17449965],\n",
       "         [ 0.16536626],\n",
       "         [ 0.03636952],\n",
       "         [ 0.13954638],\n",
       "         [ 0.33502995],\n",
       "         [ 0.20718012],\n",
       "         [-0.16513246],\n",
       "         [ 0.15368918],\n",
       "         [-1.88456088],\n",
       "         [ 0.4227796 ],\n",
       "         [ 0.11833689],\n",
       "         [ 0.60740164],\n",
       "         [ 0.32448233]])],\n",
       " '_best_intercepts': [array([ 0.02826192, -0.1032272 , -0.29833626, -0.08211869, -1.57929985,\n",
       "         -0.04649821,  0.02251887, -0.04189895, -0.07533144, -0.2042503 ,\n",
       "          0.11205144, -0.01374963,  0.21963963,  0.00974052,  0.01660807,\n",
       "          1.55271982, -0.21983446, -0.17883883,  0.00493901, -0.02249235]),\n",
       "  array([0.26651959])]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "705954fb-125b-4cb2-bd5b-e8b00bf73161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    23580.000000\n",
       "mean         0.190048\n",
       "std          0.298730\n",
       "min         -0.039990\n",
       "25%          0.006563\n",
       "50%          0.046019\n",
       "75%          0.324686\n",
       "max          1.015671\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(logistic.predict(model['train_X'])).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426121be-f029-4286-9f93-752c47216f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abd2d2e-74d7-4497-95bd-be3529385deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('identity:')\n",
    "test_performance(model,identity)\n",
    "print('\\nrelu:')\n",
    "test_performance(model,relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42ced5-5eef-40a3-ab72-f63b57a6013d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9eaea7-3a1f-4a20-ae9f-223efad8599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "param_df = pd.DataFrame()\n",
    "for k,v in relu[1].__dict__.items():\n",
    "    try:\n",
    "        param_df.loc[str(k),'specification'] = str(v)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "param_df = param_df[:31].copy()\n",
    "param_df = param_df.drop(index=[i for i in param_df.index if i.startswith('_')]).reset_index()\n",
    "param_df = param_df.rename(columns={'index':'parameter'})\n",
    "latex_table = param_df.to_latex(index=False, escape=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4290c-1b4f-48ab-9a74-33116ca67c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e474a56-48e8-4bce-81ce-a75c0ec0375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca3e09-2e40-4ea2-9c1f-2b3989e4c815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigmoid = Sequential([\n",
    "    Dense(20, activation='relu'),  # Hidden layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer with ReLU\n",
    "])\n",
    "\n",
    "sigmoid.compile(optimizer='sgd', loss='mse', metrics=['mae'])\n",
    "\n",
    "train_X = model['preprocessor'].fit_transform(model['train_X'])\n",
    "\n",
    "sigmoid.fit(train_X, model['train_y'], epochs=epochs, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c33d3d1-b200-4135-9716-cbe3f08d7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sigmoid.history.history['loss'], label='Training Loss',color='purple')\n",
    "plt.plot(sigmoid.history.history['val_loss'], label='Validation Loss', linestyle='--',color='green')\n",
    "plt.title('sigmoid')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "training_loss = sigmoid.history.history['loss']\n",
    "validation_loss = sigmoid.history.history['val_loss']\n",
    "RMSE = np.sqrt(np.mean(validation_loss))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab633b2-138b-4ed5-bd20-ba8702a4b7b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relu = Sequential([\n",
    "    Dense(20, activation='relu'),  # Hidden layer\n",
    "    Dense(1, activation='relu')  # Output layer with ReLU\n",
    "])\n",
    "\n",
    "relu.compile(optimizer='sgd', loss='mse', metrics=['mae'])\n",
    "\n",
    "train_X = model['preprocessor'].fit_transform(model['train_X'])\n",
    "\n",
    "relu.fit(train_X, model['train_y'], epochs=epochs, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034c63a1-3390-43b4-83f3-975253af0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(relu.history.history['loss'], label='Training Loss',color='purple')\n",
    "plt.plot(relu.history.history['val_loss'], label='Validation Loss', linestyle='--',color='green')\n",
    "plt.title('relu')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "training_loss = relu.history.history['loss']\n",
    "validation_loss = relu.history.history['val_loss']\n",
    "RMSE = np.sqrt(np.mean(validation_loss))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43777c29-d8f7-4c31-be45-a324930b0cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
